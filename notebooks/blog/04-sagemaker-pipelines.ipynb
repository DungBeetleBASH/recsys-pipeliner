{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create/update a `.env` file in the project root including the following environment variables.\n",
    "\n",
    "AWS_DEFAULT_SAGEMAKER_BUCKET\n",
    "\n",
    "AWS_PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = False\n",
    "START_PIPELINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../../build\n",
    "!rm -rf ../../build/*\n",
    "!cp ../pipelines/recommendations_np/code/* ../../build/\n",
    "!cp -r ../../src/pipeliner ../../build/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_path = \"../../build\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "AWS_DEFAULT_SAGEMAKER_BUCKET = os.environ.get(\"AWS_DEFAULT_SAGEMAKER_BUCKET\", None)\n",
    "DEFAULT_BUCKET_PREFIX = \"pipelines\"\n",
    "if AWS_DEFAULT_SAGEMAKER_BUCKET is None:\n",
    "    raise ValueError(\"AWS_DEFAULT_SAGEMAKER_BUCKET is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log into Docker registry with ECR credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region eu-west-1 | docker login --username AWS --password-stdin 141502667606.dkr.ecr.eu-west-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"pipeliner\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession, PipelineSession\n",
    "\n",
    "if LOCAL:\n",
    "    session = LocalPipelineSession(\n",
    "        default_bucket=AWS_DEFAULT_SAGEMAKER_BUCKET,\n",
    "        default_bucket_prefix=DEFAULT_BUCKET_PREFIX,\n",
    "    )\n",
    "    session.config = {\"local\": {\"local_code\": True}}\n",
    "else:\n",
    "    session = PipelineSession(\n",
    "        default_bucket=AWS_DEFAULT_SAGEMAKER_BUCKET,\n",
    "        default_bucket_prefix=DEFAULT_BUCKET_PREFIX,\n",
    "    )\n",
    "\n",
    "region = session.boto_region_name\n",
    "default_bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ratings_data_path = \"../pipelines/recommendations_np/data/user_item_interactions.csv.gz\"\n",
    "\n",
    "data_types = {\"user_id\": str, \"item_id\": str, \"rating\": np.float32}\n",
    "\n",
    "user_item_interactions = pd.read_csv(\n",
    "    ratings_data_path,\n",
    "    compression=\"gzip\",\n",
    "    dtype=data_types,\n",
    "    parse_dates=[\"date\"],\n",
    ")\n",
    "user_item_interactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=ratings_data_path,\n",
    "    desired_s3_uri=f\"s3://{default_bucket}/{DEFAULT_BUCKET_PREFIX}/recommender/data\",\n",
    ")\n",
    "input_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "from sagemaker.workflow.steps import CacheConfig, ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "\n",
    "class RecommenderPipeline:\n",
    "    def create(\n",
    "        self,\n",
    "        role: str,\n",
    "        name: str,\n",
    "        session: sagemaker.Session,\n",
    "        framework_version=\"1.2-1\",\n",
    "    ) -> Pipeline:\n",
    "        self.local = isinstance(session, LocalPipelineSession)\n",
    "        self.framework_version = framework_version\n",
    "\n",
    "        instance_type = ParameterString(\n",
    "            name=\"InstanceType\",\n",
    "            default_value=\"local\" if self.local else \"ml.m5.24xlarge\",\n",
    "        )\n",
    "\n",
    "        input_data = ParameterString(\n",
    "            name=\"user_item_interactions\",\n",
    "            default_value=input_data_uri,\n",
    "        )\n",
    "\n",
    "        image_uri = sagemaker.image_uris.retrieve(\n",
    "            framework=\"sklearn\",\n",
    "            region=session.boto_region_name,\n",
    "            version=\"1.2-1\",\n",
    "        )\n",
    "\n",
    "        preprocessing_cache_config = CacheConfig(\n",
    "            enable_caching=True,\n",
    "            expire_after=\"p30d\",  # 30 days\n",
    "        )\n",
    "\n",
    "        evaluation_cache_config = CacheConfig(\n",
    "            enable_caching=True,\n",
    "            expire_after=\"p30d\",  # 30 days\n",
    "        )\n",
    "\n",
    "        training_cache_config = CacheConfig(\n",
    "            enable_caching=True,\n",
    "            expire_after=\"p30d\",  # 30 days\n",
    "        )\n",
    "\n",
    "        processor = SKLearnProcessor(\n",
    "            framework_version=framework_version,\n",
    "            instance_type=instance_type,\n",
    "            instance_count=1,\n",
    "            base_job_name=\"sklearn-processor\",\n",
    "            role=role,\n",
    "            sagemaker_session=session,\n",
    "        )\n",
    "\n",
    "        user_item_interactions_input = ProcessingInput(\n",
    "            source=input_data,\n",
    "            input_name=\"user_item_interactions\",\n",
    "            destination=\"/opt/ml/processing/input/data\",\n",
    "        )\n",
    "\n",
    "        pipeliner_input = ProcessingInput(\n",
    "            source=build_path + \"/pipeliner\",\n",
    "            input_name=\"pipeliner\",\n",
    "            destination=\"/opt/ml/processing/input/code/pipeliner\",\n",
    "        )\n",
    "\n",
    "        preprocessor_step = ProcessingStep(\n",
    "            name=\"preprocessor\",\n",
    "            cache_config=preprocessing_cache_config,\n",
    "            step_args=processor.run(\n",
    "                inputs=[\n",
    "                    user_item_interactions_input,\n",
    "                    pipeliner_input,\n",
    "                ],\n",
    "                outputs=[\n",
    "                    ProcessingOutput(\n",
    "                        output_name=\"user_item_matrix\",\n",
    "                        source=\"/opt/ml/processing/output/user_item_matrix\",\n",
    "                    ),\n",
    "                    ProcessingOutput(\n",
    "                        output_name=\"item_similarity_matrix\",\n",
    "                        source=\"/opt/ml/processing/output/item_similarity_matrix\",\n",
    "                    ),\n",
    "                    ProcessingOutput(\n",
    "                        output_name=\"test_data\",\n",
    "                        source=\"/opt/ml/processing/output/test_data\",\n",
    "                    ),\n",
    "                    ProcessingOutput(\n",
    "                        output_name=\"user_encoder\",\n",
    "                        source=\"/opt/ml/processing/output/user_encoder\",\n",
    "                    ),\n",
    "                    ProcessingOutput(\n",
    "                        output_name=\"item_encoder\",\n",
    "                        source=\"/opt/ml/processing/output/item_encoder\",\n",
    "                    ),\n",
    "                ],\n",
    "                code=build_path + \"/preprocessor.py\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        sklearn_estimator = SKLearn(\n",
    "            entry_point=\"item_based_recommender.py\",\n",
    "            source_dir=build_path,\n",
    "            role=role,\n",
    "            image_uri=image_uri,\n",
    "            instance_type=instance_type,\n",
    "            sagemaker_session=session,\n",
    "            base_job_name=\"training_job\",\n",
    "            # hyperparameters=hyperparameters,\n",
    "            enable_sagemaker_metrics=True,\n",
    "            output_path=f\"s3://{default_bucket}/{DEFAULT_BUCKET_PREFIX}/recommender/model\"\n",
    "        )\n",
    "\n",
    "        item_training_step = TrainingStep(\n",
    "            name=\"item_based_recommender\",\n",
    "            estimator=sklearn_estimator,\n",
    "            cache_config=training_cache_config,\n",
    "            inputs={\n",
    "                \"item_similarity_matrix\": TrainingInput(\n",
    "                    s3_data=preprocessor_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"item_similarity_matrix\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"application/x-npz\",\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "\n",
    "        evaluation_processor = SKLearnProcessor(\n",
    "            framework_version=framework_version,\n",
    "            instance_type=instance_type,\n",
    "            instance_count=1,\n",
    "            base_job_name=\"sklearn-evaluation\",\n",
    "            role=role,\n",
    "            sagemaker_session=session,\n",
    "        )\n",
    "\n",
    "        evaluation_report = PropertyFile(\n",
    "            name=\"item_based_evaluation\",\n",
    "            output_name=\"evaluation\",\n",
    "            path=\"evaluation.json\",\n",
    "        )\n",
    "\n",
    "        evaluation_step = ProcessingStep(\n",
    "            name=\"item_based_evaluation\",\n",
    "            cache_config=evaluation_cache_config,\n",
    "            processor=evaluation_processor,\n",
    "            inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=item_training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                    destination=\"/opt/ml/processing/model\",\n",
    "                    input_name=\"model\",\n",
    "                ),\n",
    "                ProcessingInput(\n",
    "                    source=preprocessor_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"test_data\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    destination=\"/opt/ml/processing/test_data\",\n",
    "                ),\n",
    "                pipeliner_input,\n",
    "            ],\n",
    "            outputs=[\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"evaluation\",\n",
    "                    source=\"/opt/ml/processing/evaluation\",\n",
    "                ),\n",
    "            ],\n",
    "            code=\"../pipelines/recommendations_np/code/item_based_evaluation.py\",\n",
    "            property_files=[evaluation_report],\n",
    "        )\n",
    "\n",
    "        return Pipeline(\n",
    "            name=name,\n",
    "            steps=[\n",
    "                preprocessor_step,\n",
    "                item_training_step,\n",
    "                evaluation_step,\n",
    "            ],\n",
    "            sagemaker_session=session,\n",
    "            parameters=[input_data, instance_type],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = RecommenderPipeline().create(role=role, name=\"recommender\", session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "[\n",
    "    {\"Name\": step.get(\"Name\"), \"Type\": step.get(\"Type\")}\n",
    "    for step in definition.get(\"Steps\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "definition = json.loads(pipeline.definition())\n",
    "steps = definition.get(\"Steps\", {})\n",
    "for step in steps:\n",
    "    step_name = step.get(\"Name\", None)\n",
    "    step_type = step.get(\"Type\", None)\n",
    "    # step_args = step.get(\"Arguments\", {})\n",
    "    print(f\"{step_name}: {step_type}\")\n",
    "    # print(step_args.keys())\n",
    "    # output_config = step_args.get(\"ProcessingOutputConfig\", step_args.get(\"OutputDataConfig\", {}))\n",
    "    # print(json.dumps(output_config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "execution_complete = False\n",
    "\n",
    "while not execution_complete:\n",
    "    current_execution = execution.describe()\n",
    "    current_execution_name = current_execution.get(\"PipelineExecutionDisplayName\", None)\n",
    "    current_execution_status = current_execution.get(\"PipelineExecutionStatus\", None)\n",
    "    current_execution_failure_reason = current_execution.get(\"FailureReason\", None)\n",
    "    execution_complete = current_execution_status not in ('Executing','Stopping')\n",
    "    print(f\"\\nstatus: {current_execution_status}\")\n",
    "    if current_execution_failure_reason:\n",
    "        print(f\"\\nFailureReason: {current_execution_failure_reason}\")\n",
    "    if not execution_complete:\n",
    "        time.sleep(60)\n",
    "\n",
    "steps = execution.list_steps()\n",
    "for step in steps[::-1]:\n",
    "    step_name = step.get(\"StepName\", None)\n",
    "    step_status = step.get(\"StepStatus\", None)\n",
    "    failure_reasion = step.get(\"FailureReason\", None)\n",
    "    print(f\"{step_name}: {step_status}\")\n",
    "    if failure_reasion is not None:\n",
    "        print(f\"    {failure_reasion}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
